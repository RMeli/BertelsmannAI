{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8fd23ec9f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews:\n",
      "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
      "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n",
      "\n",
      "Labels:\n",
      "positive\n",
      "negative\n",
      "positiv\n"
     ]
    }
   ],
   "source": [
    "reviewsfname = \"data/IMDB-Reviews.txt\"\n",
    "labelsfname = \"data/IMDB-Labels.txt\"\n",
    "\n",
    "with open(reviewsfname, \"r\") as f:\n",
    "    reviews = f.read()\n",
    "    \n",
    "with open(labelsfname, \"r\") as f:\n",
    "    labels = f.read()\n",
    "    \n",
    "print(f\"Reviews:\\n{reviews[:1000]}\")\n",
    "print(f\"\\nLabels:\\n{labels[:25]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "print(f\"Punctuation: {punctuation}\")\n",
    "\n",
    "# Convert reviews to lowercase\n",
    "reviews = reviews.lower()\n",
    "labels = labels.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "reviews = \"\".join([char for char in reviews if char not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the']\n"
     ]
    }
   ],
   "source": [
    "allwords = reviews.split()\n",
    "\n",
    "print(allwords[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different reviews and labels are separated by newline characters in our dataset. Let's split the full text of reviews and labels into a list of reviews and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.split(\"\\n\")\n",
    "labels = labels.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t   ', 'story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers  unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting  even those from the era should be turned off  the cryptic dialogue would make shakespeare seem easy to a third grader  on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond  future stars sally kirkland and frederic forrest can be seen briefly   ']\n",
      "['positive', 'negative']\n"
     ]
    }
   ],
   "source": [
    "# Check that we have the same number of reviews and labels\n",
    "assert len(reviews) == len(labels)\n",
    "\n",
    "print(reviews[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 74072\n",
      "\n",
      "['a', 'aa', 'aaa', 'aaaaaaah', 'aaaaah', 'aaaaatch', 'aaaahhhhhhh', 'aaaand', 'aaaarrgh', 'aaah', 'aaargh', 'aaaugh', 'aaawwwwnnn', 'aachen', 'aada', 'aadha', 'aag', 'aage', 'aaghh', 'aah', 'aahhh', 'aaip', 'aaja', 'aakash', 'aaker', 'aakrosh', 'aaliyah', 'aames', 'aamir', 'aan']\n"
     ]
    }
   ],
   "source": [
    "words = sorted(set(allwords))\n",
    "n_words = len(words)\n",
    "\n",
    "print(f\"Number of unique words: {n_words}\")\n",
    "print(f\"\\n{words[:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word to int mapping with 1 as first index\n",
    "word2int = {word : i for i, word in enumerate(words, 1)}\n",
    "\n",
    "# Create inverse int to word mapping\n",
    "int2word = {i : word for word, i in word2int.items()}\n",
    "\n",
    "# Check conversion\n",
    "assert len(word2int) == len(int2word)\n",
    "for word in words:\n",
    "    assert word == int2word[word2int[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviw 1:\n",
      "['bromwell', 'high', 'is', 'a', 'cartoon']\n",
      "\n",
      "Encoded Review 1:\n",
      "[8210, 29951, 33665, 1, 9819]\n",
      "\n",
      "Encoding:\n",
      "\n",
      "bromwell     => 8210\n",
      "high         => 29951\n",
      "is           => 33665\n",
      "a            => 1\n",
      "cartoon      => 9819\n",
      "\n",
      "Encoded Revies Shape: (25001,)\n"
     ]
    }
   ],
   "source": [
    "encodedreviews = []\n",
    "for review in reviews:\n",
    "    encodedreviews.append([word2int[word] for word in review.split()])\n",
    "\n",
    "# Visualize and check encoding\n",
    "print(f\"Reviw 1:\\n{reviews[0].split()[:5]}\")\n",
    "print(f\"\\nEncoded Review 1:\\n{encodedreviews[0][:5]}\")\n",
    "print(f\"\\nEncoding:\\n\")\n",
    "for word in reviews[0].split()[:5]:\n",
    "    print(f\"{word:12} => {word2int[word]}\")\n",
    "    \n",
    "encodedreviews = np.array(encodedreviews)\n",
    "print(f\"\\nEncoded Revies Shape: {encodedreviews.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "['positive', 'negative', 'positive', 'negative', 'positive']\n",
      "\n",
      "Encoded Labels:\n",
      "[1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "encodedlabels = []\n",
    "for label in labels:\n",
    "    encodedlabels.append(0 if label == \"negative\" else 1)\n",
    "    \n",
    "# Visualize and check labels\n",
    "print(f\"Labels:\\n{labels[:5]}\")\n",
    "print(f\"\\nEncoded Labels:\\n{encodedlabels[:5]}\")\n",
    "\n",
    "# Transform labels to numpy array\n",
    "encodedlabels = np.array(encodedlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Short and Very Long Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Review Length: 0\n",
      "Maximum Review Length: 2514\n",
      "Average Review Length: 240.798\n",
      "Review Length STD: 179.017\n"
     ]
    }
   ],
   "source": [
    "reviewlenghts = [len(review) for review in encodedreviews]\n",
    "\n",
    "reviewlenghts = np.array(reviewlenghts)\n",
    "\n",
    "print(f\"Minimum Review Length: {np.min(reviewlenghts)}\")\n",
    "print(f\"Maximum Review Length: {np.max(reviewlenghts)}\")\n",
    "print(f\"Average Review Length: {np.mean(reviewlenghts):.3f}\")\n",
    "print(f\"Review Length STD: {np.std(reviewlenghts):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(reviewlenghts, bins=len(reviewlenghts)//100)\n",
    "plt.axvline(np.mean(reviewlenghts), color=\"orange\", )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the very short reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this movie is terrible but it has some good effects   \n",
      "\n",
      "ming the merciless does a little bardwork and a movie most foul   \n",
      "\n",
      "comment this movie is impossible  is terrible  very improbable  bad interpretation e direction  not look       \n",
      "\n",
      "i wouldn  t rent this one even on dollar rental night   \n",
      "\n",
      "you  d better choose paul verhoeven  s even if you have watched it   \n",
      "\n",
      "adrian pasdar is excellent is this film  he makes a fascinating woman   \n",
      "\n",
      "no comment  stupid movie  acting average or worse    screenplay  no sense at all    skip it   \n",
      "\n",
      "long  boring  blasphemous  never have i been so glad to see ending credits roll   \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = np.where(reviewlenghts <= 15)[0]\n",
    "\n",
    "for idx in idxs:\n",
    "    print(reviews[idx], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Reviews Shape: (25000,)\n",
      "Encoded Labels Shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "encodedreviews = encodedreviews[reviewlenghts > 0] \n",
    "encodedlabels = encodedlabels[reviewlenghts > 0]\n",
    "\n",
    "print(f\"Encoded Reviews Shape: {encodedreviews.shape}\")\n",
    "print(f\"Encoded Labels Shape: {encodedlabels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncation and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ... 33768 33726 64394]\n",
      " [    0     0     0 ...  5272 57783  8031]\n",
      " [30468 46281 30894 ... 56131 73092 46049]\n",
      " ...\n",
      " [    0     0     0 ... 15007 60837  4144]\n",
      " [    0     0     0 ... 46549 71568 25211]\n",
      " [    0     0     0 ... 65773 33665 47191]]\n"
     ]
    }
   ],
   "source": [
    "len_sequence = 250 # Total number of word in a review\n",
    "\n",
    "paddedreviews = np.zeros((encodedreviews.size, len_sequence), dtype=int)\n",
    "\n",
    "for i, review in enumerate(encodedreviews):\n",
    "    paddedreviews[i,-len(review):] = review[:len_sequence]\n",
    "    \n",
    "print(paddedreviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews Train: (20000, 250)\n",
      "Labels Train: (20000,)\n"
     ]
    }
   ],
   "source": [
    "reviews_train, reviews_vt, labels_train, labels_vt = train_test_split(paddedreviews, encodedlabels, test_size=0.2)\n",
    "print(f\"Reviews Train: {reviews_train.shape}\\nLabels Train: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews Valid: (2500, 250)\n",
      "Labels Valid: (2500,)\n",
      "Reviews Test: (2500, 250)\n",
      "Labels Test: (2500,)\n"
     ]
    }
   ],
   "source": [
    "reviews_valid, reviews_test, labels_valid, labels_test = train_test_split(reviews_vt, labels_vt, test_size=0.5)\n",
    "print(f\"Reviews Valid: {reviews_valid.shape}\\nLabels Valid: {labels_valid.shape}\")\n",
    "print(f\"Reviews Test: {reviews_test.shape}\\nLabels Test: {labels_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders and Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TensorDataset(torch.from_numpy(reviews_train), torch.from_numpy(labels_train))\n",
    "validset = TensorDataset(torch.from_numpy(reviews_valid), torch.from_numpy(labels_valid))\n",
    "testset = TensorDataset(torch.from_numpy(reviews_test), torch.from_numpy(labels_test))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "validloader = DataLoader(validset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "testloader = DataLoader(testset, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape: torch.Size([100, 250])\n",
      "Features:\n",
      "tensor([[    0,     0,     0,  ..., 25370, 71489, 33768],\n",
      "        [31424, 55987,     1,  ..., 24476,  1638, 65773],\n",
      "        [31424, 26653, 65773,  ..., 66391, 32081, 43774],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     1, 49303, 53008],\n",
      "        [    0,     0,     0,  ..., 32081, 65543, 65547],\n",
      "        [    0,     0,     0,  ..., 65543, 22421, 57043]])\n",
      "Labels Shape: torch.Size([100])\n",
      "Labels:\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "trainiter = iter(trainloader)\n",
    "\n",
    "features, labels = next(trainiter)\n",
    "\n",
    "print(f\"Features Shape: {features.shape}\")\n",
    "print(f\"Features:\\n{features}\")\n",
    "print(f\"Labels Shape: {labels.shape}\")\n",
    "print(f\"Labels:\\n{labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Architecture for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_words, # Number of words \n",
    "                 s_embedding, # Embedding size\n",
    "                 s_hidden, # Hidden layer size\n",
    "                 n_layers, # Number of LSTM layers\n",
    "                 dropp=0.5 # Dropout probability\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        n_words += 1 # Add one word for 0 padding\n",
    "        \n",
    "        self.s_hidden = s_hidden\n",
    "        \n",
    "        # Embedding layer to avoid one-hot-encoding all words\n",
    "        # Reduce n_words to s_embedding for LSTM input\n",
    "        self.embedding = nn.Embedding(n_words, s_embedding)\n",
    "        \n",
    "        # Define LSTM layer with embedding input\n",
    "        self.lstm = nn.LSTM(s_embedding, s_hidden, n_layers, dropout=dropp, batch_first=True)\n",
    "        \n",
    "        # Define dropout layer between LSTM and FC\n",
    "        self.dropout = nn.Dropout(dropp)\n",
    "        \n",
    "        # Fully connected layer with one output\n",
    "        # One ouptut for binary classification (positive/negative)\n",
    "        self.fc = nn.Linear(s_hidden, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        x = x.reshape(-1, self.s_hidden)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Apply sigmoid function\n",
    "        # Returns values between 0 and 1\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        # Respahe\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        \n",
    "        # Get last batch\n",
    "        x = x[:, -1]\n",
    "        \n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(74073, 500)\n",
      "  (lstm): LSTM(500, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "s_embedding = 500\n",
    "s_hidden = 256\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentRNN(n_words, s_embedding, s_hidden, n_layers)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0/5\n",
      "--- Epoch 0/5\n",
      "    Step: 100\n",
      "    Validation Loss: 22.65956\n",
      "--- Epoch 0/5\n",
      "--- Epoch 0/5\n",
      "    Step: 200\n",
      "    Validation Loss: 19.50708\n",
      "--- Epoch 1/5\n",
      "--- Epoch 1/5\n",
      "    Step: 300\n",
      "    Validation Loss: 18.35487\n",
      "--- Epoch 1/5\n",
      "--- Epoch 1/5\n",
      "    Step: 400\n",
      "    Validation Loss: 20.99881\n",
      "--- Epoch 2/5\n",
      "--- Epoch 2/5\n",
      "    Step: 500\n",
      "    Validation Loss: 22.92652\n",
      "--- Epoch 2/5\n",
      "--- Epoch 2/5\n",
      "    Step: 600\n",
      "    Validation Loss: 29.91030\n",
      "--- Epoch 3/5\n",
      "--- Epoch 3/5\n",
      "    Step: 700\n",
      "    Validation Loss: 33.07872\n",
      "--- Epoch 3/5\n",
      "--- Epoch 3/5\n",
      "    Step: 800\n",
      "    Validation Loss: 34.72533\n",
      "--- Epoch 4/5\n",
      "--- Epoch 4/5\n",
      "    Step: 900\n",
      "    Validation Loss: 44.08817\n",
      "--- Epoch 4/5\n",
      "--- Epoch 4/5\n",
      "    Step: 1000\n",
      "    Validation Loss: 46.69334\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "print_every = len(trainloader) // 2\n",
    "\n",
    "model.train()\n",
    "\n",
    "steps = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    hidden = None\n",
    "    \n",
    "    for review, label in trainloader:\n",
    "        \n",
    "        steps += 1\n",
    "        \n",
    "        # Reset optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        review, label = review.to(device), label.to(device)\n",
    "        \n",
    "        output, hidden = model(review, hidden)\n",
    "        \n",
    "        hidden = tuple([h.detach() for h in hidden])\n",
    "        \n",
    "        loss = loss_function(output.squeeze(), label.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                hidden_v = None\n",
    "                \n",
    "                loss_v = 0\n",
    "                \n",
    "                for rewiev, label in validloader:\n",
    "                    \n",
    "                    review, label = review.to(device), label.to(device)\n",
    "                    \n",
    "                    output, hidden_v = model(review, hidden_v)\n",
    "                    \n",
    "                    loss_v += loss_function(output.squeeze(), label.float()).item()\n",
    "                    \n",
    "            print(f\"--- Epoch {epoch}/{epochs}\")\n",
    "            print(f\"    Step: {steps}\")\n",
    "            print(f\"    Validation Loss: {loss_v/len(validloader):.5f}\")\n",
    "                    \n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
